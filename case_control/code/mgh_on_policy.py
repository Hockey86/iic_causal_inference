# -*- coding: utf-8 -*-
"""MGH.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1328EbQmeZ9maTWn5AGkikTTttcHecddR

# Setting up
"""

import sys
import os
#!{sys.executable} -m pip install keras-rl

import numpy as np
import pickle

import neuralnet 

import torch
import torch.nn as nn

import matplotlib.pyplot as plt

#import gym
#from gym import spaces
#from gym.utils import seeding
#
#from keras.models import Sequential
#from keras.layers import Dense, Activation, Flatten
#from keras.optimizers import Adam
#
#from rl.agents.dqn import DQNAgent
#from rl.policy import EpsGreedyQPolicy
#from rl.memory import SequentialMemory

#import pickle
#
#from sklearn.ensemble import RandomForestRegressor as RFR
#from sklearn.svm import SVR
#
#import sklearn.linear_model as lm
#
#import sklearn.neural_network as nn

#import torch
#import torch.nn as nn

datafile = open('../IICdata/preprocessed_dataset_all.pickle','rb')
data = pickle.load( datafile , encoding='latin')

big_datafile = open('../IICdata/for_Harsh/data/big_dataset.pickle','rb')
big_dataset = pickle.load( big_datafile , encoding='latin')

featurefile = open('../IICdata/for_Harsh/data/features_window_600.pickle','rb')
features = pickle.load( featurefile , encoding='latin')



"""# Q-Learning
Defining the model
"""



class QLearning:
    def __init__( self, state_space_dimension, action_space_dimension, covariate_space_dimension ):
        self.state_space_dimension = state_space_dimension
        self.action_space_dimension = action_space_dimension
        self.covariate_space_dimension = covariate_space_dimension
        self.Q = neuralnet.Net(self.state_space_dimension+self.action_space_dimension+self.covariate_space_dimension,1,[200])
        self.A = neuralnet.Net(self.state_space_dimension+self.covariate_space_dimension,self.action_space_dimension,[300])
    
    def fit( self, features, learningrate=0.01, losscutoff=50000, verbose=False ):
        Y = features['Y']
        C = features['C']
        E = features['E']
        D = features['D']
        n = len(Y)
        for j in range(0,100):
            for i in range(0,n):
                #first learn last step
                yi = Y[i]
                ci = C[i]
                Ei = E[i]
                Di = D[i]
                T,sd = Ei.shape
                _,ad = Di.shape
                t = T-1
                vec_t = torch.tensor([ np.hstack( (Ei[t],Di[t],ci) ) ],dtype=torch.float)
                if yi == 0 or yi == 1 or yi == 2:
                    val_t1 = torch.tensor([[ 10000/(yi+1) ]],dtype=torch.float)
                elif yi == 3:
                    val_t1 = torch.tensor([[ 0 ]],dtype=torch.float)
                else:
                    val_t1 = torch.tensor([[ -2500*yi ]],dtype=torch.float)
                self.Q.fit(x=vec_t,y=val_t1,learningrate=learningrate,losscutoff=losscutoff,verbose=verbose)
        for itr in range(50*n):
            #learn random steps
            i = np.random.randint(0,n)
            yi = Y[i]
            ci = C[i]
            Ei = E[i]
            Di = D[i]
            T,sd = Ei.shape
            _,ad = Di.shape
            t = np.random.randint(0,T)
            vec_t = torch.tensor([ np.hstack( (Ei[t],Di[t],ci) ) ],dtype=torch.float)
            if (t+1)<T and itr>100:
                vec1_t1 = torch.tensor([ np.hstack( (Ei[t+1],ci) ) ],dtype=torch.float)
                Di1 = torch.tensor([ Di[t+1]], dtype=torch.float )
                vec2_t1 = torch.cat( [ torch.tensor( Ei[t+1], dtype=torch.float ), Di1[0], torch.tensor(ci,dtype=torch.float) ])
                #torch.tensor([ np.hstack( (Ei[t+1],Di1,ci) ) ],dtype=torch.float)
                val_t1 = self.Q(vec2_t1)
                if verbose:
                    print('fitting action function')
                self.A.fit(x=vec1_t1,loss=-val_t1,learningrate=learningrate,losscutoff=losscutoff,verbose=verbose)
            else:
                if yi == 0 or yi == 1 or yi == 2:
                    val_t1 = torch.tensor([[ 10000/(yi+1) ]],dtype=torch.float)
                elif yi == 3:
                    val_t1 = torch.tensor([[ 0 ]],dtype=torch.float)
                else:
                    val_t1 = torch.tensor([[ -2500*yi ]],dtype=torch.float)
            if verbose:
                print('fitting Q function')
            self.Q.fit(x=vec_t,y=val_t1,learningrate=learningrate,losscutoff=losscutoff,verbose=verbose)
        return self
    

Y = features['Y']
C = features['C']
E = features['E']
D = features['D']

QL_on_policy = QLearning(state_space_dimension=17,action_space_dimension=34,covariate_space_dimension=61)
QL_on_policy = QL_on_policy.fit(features,learningrate=0.0000005,losscutoff=101296,verbose=True)

file = open('Q_outcome.csv','w') 
Q_on_policy_last = []
for i in range(0,1308):
    Q_on_policy_last.append( float(QL_on_policy.Q(torch.tensor([ np.hstack( (E[i][-1],D[i][-1],C[i]) ) ],dtype=torch.float) )[0][0] ) )
    print(QL_on_policy.Q(torch.tensor([ np.hstack( (E[i][-1],D[i][-1],C[i]) ) ],dtype=torch.float) )[0],Y[i],sep=', ',file=file)
file.close()

#making boxplots
def reject_outliers(data, m=2):
    return data[abs(data - np.mean(data)) < m * np.std(data)]

uniques = list(np.unique(Y))
d_on_policy = [ [] for i in range(0,len(uniques))]
for i in range(0,len(Y)):
    d_on_policy[ uniques.index(Y[i]) ] = d_on_policy[ uniques.index(Y[i]) ] + [Q_on_policy_last[i]]

d_on_policy = [ reject_outliers(np.array(d_on_policy[i])) for i in range(0,len(uniques))]
plt.violinplot(d_on_policy,showmeans=False, showextrema=True, showmedians=True)
plt.xticks([1,2,3,4,5,6,7],uniques,rotation=15)
