# -*- coding: utf-8 -*-
"""MGH.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1328EbQmeZ9maTWn5AGkikTTttcHecddR

# Setting up
"""

import sys
import os
import time
#!{sys.executable} -m pip install keras-rl

import numpy as np
import pickle
import pandas as pd

import neuralnet 

import torch
import torch.nn as nn

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import seaborn as sns

import sklearn.linear_model as linearmodel
import sklearn.ensemble as ensemble
import sklearn.svm as svm
from bartpy.sklearnmodel import SklearnModel as bart
from sklearn.model_selection import cross_validate
from sklearn.cluster import DBSCAN
from sklearn.svm import SVR

import scipy.optimize as opt

#import gym
#from gym import spaces
#from gym.utils import seeding
#
#from keras.models import Sequential
#from keras.layers import Dense, Activation, Flatten
#from keras.optimizers import Adam
#
#from rl.agents.dqn import DQNAgent
#from rl.policy import EpsGreedyQPolicy
#from rl.memory import SequentialMemory

#import pickle
#
#from sklearn.ensemble import RandomForestRegressor as RFR
#from sklearn.svm import SVR
#
#import sklearn.linear_model as lm
#
#import sklearn.neural_network as nn

#import torch
#import torch.nn as nn
window = 600
datafile = open('../IICdata/preprocessed_dataset_all.pickle','rb')
data = pickle.load( datafile , encoding='latin')

big_datafile = open('../IICdata/for_Harsh/data/big_dataset.pickle','rb')
big_dataset = pickle.load( big_datafile , encoding='latin')

featurefile = open('../IICdata/for_Harsh/data/features_window_%d.pickle'%(window),'rb')
features = pickle.load( featurefile , encoding='latin')



"""# Q-Learning
Defining the model
"""



class QLearning:
    def __init__( self, state_space_dimension, action_space_dimension, covariate_space_dimension, reward = ( lambda x: 0 ), discount=1, off_policy=True, model='ridge' ):
        self.state_space_dimension = state_space_dimension
        self.action_space_dimension = action_space_dimension
        self.covariate_space_dimension = covariate_space_dimension
        self.model = model
        if self.model=='bart':
            self.Q = bart()
            self.A = lambda s1,c: opt.minimize(fun = lambda a1: -1*self.Q.predict([np.hstack((s1,a1,c))])[0], x0 = np.zeros((self.action_space_dimension,)), method='CG').x
            self.S = bart()
        if self.model=='ridge':
            self.Q = linearmodel.Ridge()
            self.A = lambda s1,c: opt.minimize(fun = lambda a1: -1*self.Q.predict([np.hstack((s1,a1,c))])[0], x0 = np.zeros((self.action_space_dimension,)), method='CG').x
            self.S = linearmodel.Ridge()
        if self.model=='random-forest':
            self.Q = ensemble.RandomForestRegressor()
            self.A = lambda s1,c: opt.minimize(fun = lambda a1: -1*self.Q.predict([np.hstack((s1,a1,c))])[0], x0 = np.zeros((self.action_space_dimension,)), method='CG').x
            self.S = ensemble.RandomForestRegressor(n_estimators=1000)
        if self.model=='neural-net':
            self.Q = neuralnet.Net(self.state_space_dimension+self.action_space_dimension+self.covariate_space_dimension,1,[16],isOutputPositive=0)
            self.A = neuralnet.Net(self.state_space_dimension+self.action_space_dimension+self.covariate_space_dimension,self.action_space_dimension,[48],isOutputPositive=1)
            self.S = neuralnet.Net(self.state_space_dimension+self.action_space_dimension+self.covariate_space_dimension,self.state_space_dimension,[32],isOutputPositive=1)
        self.off_policy = off_policy
        self.discount = discount
        self.reward = reward
        self.lag = 1
        self.forecast = 1
    
    def fit( self, features, learningrate=0.05, losscutoff=1001296, verbose=False, itr=5):
        Y = features['Y']
        C = features['C']
        E = features['E']
        D = features['D']
        Y_val = features['Y_val']
        N = len(Y)
        if self.model=='ridge' or self.model=='random-forest':
            #first fit the last step
            XE = np.array([ E[i][-1] for i in range(0,N) ])
            XD = np.array([ D[i][-1] for i in range(0,N) ])
            X = np.hstack((XE,XD,C))
            self.Q = self.Q.fit(X,Y_val)
            
            #now learn other steps
            for itrtn in range(0,itr):
                for i in range(0,N):
                    T,ps = E[i].shape
                    if T>2:
                        XCi = np.array([ C[i] for t in range(0,T) ])
                        Xi = np.hstack((E[i],D[i],XCi))
                        XE1i = E[i][1:,:]
                        if self.off_policy:
                            A1i = np.array([ self.A( E[i][t+1],C[i] ) for t in range(0,T-1) ])
                        else:
                            A1i = D[i][1:,:]
                        #print((np.shape(XE1i),np.shape(A1i),np.shape(XCi[:T-1,:])) )
                        X1i = np.hstack((XE1i,A1i,XCi[:T-1,:]))
                        Y_vali = np.hstack( ( self.discount*self.Q.predict(X1i) + np.array([self.reward(E[i][t],D[i][t]) for t in range(0,T-1)]), np.array([ Y_val[i] ]) ) )
                        if i==0:
                            X = Xi
                            Y_val = Y_vali
                        else:
                            X = np.vstack((X,Xi))
                            Y_val = np.hstack((Y_val,Y_vali))
                self.Q = self.Q.fit(X,Y_val)
        return self
                
    def fit_simulator( self, features, lag=1, forecast=5, learningrate=0.05, losscutoff=1001296, verbose=False):
        Y = features['Y']
        C = features['C']
        E = features['E']
        D = features['D']
        N = len(Y)
        self.lag = lag
        self.forecast = forecast
        if self.model=='ridge' or self.model=='random-forest':
            X = []
            Out = []
            for itrtn in range(0,1):
                for i in range(0,N): #for a particular patient:
                    T,ps = E[i].shape #time they are in observation
                    if T>lag+1: #checking if they are long enough there
                        for t in range(0,T-(lag+forecast)+1):
                            ex, dx, cx = E[i][t:t+lag,:].reshape(1,-1)[0], D[i][t:t+lag,:].reshape(1,-1)[0], C[i]
                            Xit = np.hstack((ex,dx,cx)) 
                            Yit = E[i][t+lag:t+lag+forecast,:].reshape(1,-1)[0]
                            X.append(Xit)
                            Out.append(Yit)
            X = np.array(X)
#            sample_weights = 10000*(np.sum(X[:,2*lag:4*lag],axis=1)) + 1
            scores = cross_validate(self.S,np.array(X),np.array(Out),cv=5)
            print(np.mean(scores['test_score']))
            self.S = self.S.fit(np.array(X),np.array(Out))  
            print(self.S.score(np.array(X),np.array(Out)))                  
        return self
    
    def run_simulator(self, init_features,D_forecast=[],T=20):
        C = init_features['C'] #C, only for one person, length = 1
        E = init_features['E'] #E, only for one person, length = lag
        D = init_features['D'] #D, only for one person, length = lag-1    
        lag = self.lag
        for t in range(0,T):
            if len(D_forecast)<T-1:
                D1 = self.A(E[-1,:],C) #predict this step action
            else:
                D1 = D_forecast[t]
            if len(D)>0:
                D = np.vstack((D,D1))
            else:
                D = D1.reshape(1,-1)
            ex, dx, cx = E[-lag:,:].reshape(1,-1)[0], D[-lag:,:].reshape(1,-1)[0], C
            Xit = np.hstack((ex,dx,cx)) 
            E1 = self.S.predict(Xit.reshape(1,-1)) #predicting next K steps
            E1 = E1.reshape((self.forecast,2))
            E = np.vstack((E,E1[0,:].reshape(1,-1)))
        return E,D
            
    
def f(y):
    if y==0 or y==1 or y==2:
        return 0
    elif y==3 or y==4 or y==5:
        return -5
    elif y==6:
        return -20
    
def preprocess(features):
    Y = list(features['Y'])
    Y_val = list(features['Y_val'])
    C = list(features['C'])
    E = features['E']
    D = features['D']
    n = len(Y)
    i = 0
    while(i<n):
        if np.sum( D[i] ) == 0:
            n = n-1
            del(Y[i])
            del(Y_val[i])
            del(C[i])
            del(E[i])
            del(D[i])
        else:
            Ei = np.hstack( ( np.sum(E[i][:,:4],axis=1).reshape(-1,1), np.mean(E[i][:,4:],axis=1).reshape(-1,1) ) )
            E[i] = Ei
            i += 1
    featureprime = {}
    featureprime['Y'] = np.array(Y)
    featureprime['Y_val'] = np.array(Y_val)
    featureprime['C'] = np.array(C)
    featureprime['E'] = E
    featureprime['D'] = D
    featureprime['Ename'] = ['IIC Ratio','DischargeFreq']
    featureprime['Dname'] = ['NSAED','AED']
    return featureprime

def align_1_nsaed_neigborhood(features,k=5):
    E = features['E']
    D = features['D']
    n = len(E)
    snapshot = {'E':[],'D':[],'idx':[]}
    for i in range(0,n):
        Ei = E[i]
        Di1 = D[i][:,0]
        T = len(Di1)
        for t in range(T):
            dit = Di1[t]
            if dit>0:
                st = min( t, k )
                et = min( (T)-t, k+1 )
                dsnap = Di1[t-st:t+et]
                esnap = Ei[t-st:t+et,:]
                snapshot['E'] = snapshot['E'] + [esnap]
                snapshot['D'] = snapshot['D'] + [dsnap]
                snapshot['idx'] = snapshot['idx'] + [i]
    return snapshot

def align_0_nsaed_neigborhood(features,k=5):
    E = features['E']
    D = features['D']
    n = len(E)
    snapshot = {'E':[],'D':[],'idx':[]}
    for i in range(0,n):
        Ei = E[i]
        Di1 = D[i][:,0]
        T = len(Di1)
        for t in range(T):
            dit = Di1[t]
            if dit==0:
                st = min( t, k )
                et = min( (T)-t, k+1 )
                dsnap = Di1[t-st:t+et]
                esnap = Ei[t-st:t+et,:]
                snapshot['E'] = snapshot['E'] + [esnap]
                snapshot['D'] = snapshot['D'] + [dsnap]
                snapshot['idx'] = snapshot['idx'] + [i]
    return snapshot

def filter_eqlen(snapshot,l=11):
    snapshot_f = {'E':[],'D':[],'idx':[]}
    D = snapshot['D']
    E = snapshot['E']
    idx = snapshot['idx']
    for i in range(len(D)):
        if len(D[i])==l:
            snapshot_f['D'] = snapshot_f['D'] + [D[i]]
            snapshot_f['E'] = snapshot_f['E'] + [E[i]]
            snapshot_f['idx'] = snapshot_f['idx'] + [idx[i]]
    return snapshot_f

def filter_0_eqlen(snapshot,l=11):
    snapshot_f = {'E':[],'D':[],'idx':[]}
    D = snapshot['D']
    E = snapshot['E']
    idx = snapshot['idx']
    for i in range(len(D)):
        if len(D[i])==l:
            if np.sum(D[i][:(l//2)])==0:
                snapshot_f['D'] = snapshot_f['D'] + [D[i]]
                snapshot_f['E'] = snapshot_f['E'] + [E[i]]
                snapshot_f['idx'] = snapshot_f['idx'] + [idx[i]]
    return snapshot_f

def filter_00_eqlen(snapshot,l=10):
    snapshot_f = {'E':[],'D':[],'idx':[]}
    D = snapshot['D']
    E = snapshot['E']
    idx = snapshot['idx']
    for i in range(len(D)):
        if len(D[i])==l:
            if np.sum(D[i][:(l//2)])==0 and np.sum(D[i][(l//2)+2:])==0:
                snapshot_f['D'] = snapshot_f['D'] + [D[i]]
                snapshot_f['E'] = snapshot_f['E'] + [E[i]]
                snapshot_f['idx'] = snapshot_f['idx'] + [idx[i]]
    return snapshot_f

def ase(yhat,y):
    e = np.abs(yhat - y)
    scale = 1#+np.mean(np.abs(y[1:] - y[:-1]))
    return e/scale

def dist_snapshot(s1,s2):
    T = len(s1)
    diff = s1[:T//2,:]-s2[:T//2,:]
    d = np.matmul(diff.T,diff)
    return np.linalg.norm(d,ord=1)
    
Y = features['Y']
C = features['C']
Eprime = features['E']
E = [Eprime[i][:,np.array([0,1,2,3,5,7,9])] for i in range(0,len(Eprime))]
Dprime = features['D']
D = [Dprime[i][:,np.array([0,1])] for i in range(0,len(Dprime))]
Enameprime = np.array(features['Enames'])
Dnameprime = np.array(features['Dnames'])
Ename = Enameprime[np.array([0,1,2,3,5,7,9])]
Dname = Dnameprime[np.array([0,1])]
Cname = features['Cnames']
Y_val = np.array(list(map(f,Y)))
features['Y_val'] = Y_val

featureprime = {}
featureprime['Y'] = Y
featureprime['C'] = C
featureprime['E'] = E
featureprime['D'] = D
featureprime['Ename'] = Ename
featureprime['Dname'] = Dname
featureprime['Cname'] = Cname
featureprime['Y_val'] = Y_val

featureprime = preprocess(featureprime)

times = int(time.time())

##off_policy
torch.manual_seed(0)
np.random.seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

def reward_mgh(Eit,Dit):
    return 0

lag = 10
forecast = 20
Ename = featureprime['Ename']
Dname = featureprime['Dname']
QL_off_policy = QLearning(state_space_dimension=7,action_space_dimension=2,covariate_space_dimension=61, off_policy=True, reward = reward_mgh, discount=1, model='random-forest')
#QL_off_policy = QL_off_policy.fit(featureprime,verbose=False,itr=1)
QL_off_policy = QL_off_policy.fit_simulator(featureprime, lag=lag, forecast=forecast, verbose=False)

forecast_range = 50
ase_df = pd.DataFrame()
for case in range(0,1000):
    try:
        init_features = {}
        init_features['E'] = E[case][:QL_off_policy.lag,:]
        init_features['D'] = D[case][:QL_off_policy.lag-1,:]
        init_features['C'] = C[case]
        df_temp = pd.DataFrame()
        Esim, Dsim = QL_off_policy.run_simulator(init_features, D_forecast=D[case][QL_off_policy.lag-1:,:], T=forecast_range)
        baseline_iic = list(E[case][:QL_off_policy.lag,0]) + list(E[case][QL_off_policy.lag-1,0]*np.ones((forecast_range,)))
        baseline_disfreq = list(E[case][:QL_off_policy.lag,1]) + list(E[case][QL_off_policy.lag-1,1]*np.ones((forecast_range,)))
        df_temp['t'] = np.arange(-QL_off_policy.lag+1,forecast_range+1)*10
        df_temp['ASE_IIC_Ratio'] = ase(Esim[:,0],E[case][:len(Esim),0])
        df_temp['ASE_Discharge_Freq'] = ase(Esim[:,1],E[case][:len(Esim),1])
        df_temp['ASE_baseline_IIC_Ratio'] = ase(baseline_iic,E[case][:len(baseline_iic),0])
        df_temp['ASE_baseline_Discharge_Freq'] = ase(baseline_disfreq,E[case][:len(baseline_disfreq),1])
        ase_df = ase_df.append(df_temp)
    except:
        continue
    
fig = plt.figure(figsize=(8.75,7))
#sns.lineplot(x='t',y='ASE_IIC_Ratio',data=ase_df)
sns.lineplot(x='t',y='ASE_Discharge_Freq',data=ase_df)
sns.lineplot(x='t',y='ASE_baseline_Discharge_Freq',data=ase_df,dashes=True)
#sns.lineplot(x='t',y='ASE_baseline_IIC_Ratio',data=ase_df,dashes=True)
plt.ylabel('ASE')
plt.xlabel('time (minutes)')
plt.legend(['IIC Ratio','Baseline IIC Ratio'])
fig.savefig('ASE_IIC_Ratio_%d.png'%(forecast_range))